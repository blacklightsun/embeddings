{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем PyTorch и модуль nn\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала задаем гиперпараметры нашей модели\n",
    "\n",
    "# размер контекста - # 2 слова слева, 2 справа \n",
    "# - это наше контекстное окно\n",
    "CONTEXT_SIZE = 2 \n",
    "# размерность матрицы эмбеддингов\n",
    "EMBEDDING_DIM = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To', \"Kara's\", 'astonishment,', 'she', 'discovers', 'that', 'a', 'portal', 'has', 'opened', 'in', 'her', 'bedroom', 'closet', 'and', 'two', 'goblins', 'have', 'fallen', 'through!', 'They', 'refuse', 'to', 'return', 'to', 'the', 'fairy', 'realms', 'and', 'be', 'drafted', 'for', 'an', 'impending', 'war.', 'In', 'an', 'attempt', 'to', 'roust', 'the', 'pesky', 'creatures,', 'Kara', 'falls', 'through', 'the', 'portal,', 'smack', 'into', 'the', 'middle', 'of', 'a', 'huge', 'war.', 'Kara', 'meets', 'Queen', 'Selinda,', 'who', 'appoints', 'Kara', 'as', 'a', 'Fairy', 'Princess', 'and', 'assigns', 'her', 'an', 'impossible', 'task:', 'to', 'put', 'an', 'end', 'to', 'the', 'war', 'using', 'her', 'diplomatic', 'skills.']\n"
     ]
    }
   ],
   "source": [
    "# наш крошечный обучающий набор, разбиваем его на слова\n",
    "\n",
    "raw_text = \"\"\"To Kara's astonishment, she discovers that a portal has opened \n",
    "in her bedroom closet and two goblins have fallen through! They refuse to\n",
    "return to the fairy realms and be drafted for an impending war. In an attempt\n",
    "to roust the pesky creatures, Kara falls through the portal,\n",
    "smack into the middle of a huge war. Kara meets Queen Selinda, who appoints\n",
    "Kara as a Fairy Princess and assigns her an impossible task:\n",
    "to put an end to the war using her diplomatic skills.\"\"\".split()\n",
    "\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем словарь, оставив в списке \n",
    "# только уникальные слова\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diplomatic', 'through!', 'who', 'Princess', 'portal', 'smack', 'has', 'and', 'They', 'in', 'goblins', 'return', 'have', 'Fairy', 'impending', 'an', 'meets', 'Kara', 'her', 'that', 'war', 'bedroom', 'to', 'she', \"Kara's\", 'portal,', 'huge', 'task:', 'end', 'a', 'To', 'be', 'astonishment,', 'falls', 'Selinda,', 'appoints', 'creatures,', 'of', 'through', 'impossible', 'fallen', 'put', 'closet', 'fairy', 'drafted', 'into', 'two', 'attempt', 'In', 'refuse', 'war.', 'middle', 'discovers', 'for', 'Queen', 'opened', 'assigns', 'using', 'the', 'realms', 'roust', 'skills.', 'pesky', 'as'}\n"
     ]
    }
   ],
   "source": [
    "# смотрим словарь\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "# смотрим размер словаря\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мы создаем простые отображения слов в элементы \n",
    "# – значения Python’овского словаря и наоборот\n",
    "word_to_ix = {word: ix for ix, word in enumerate(vocab)}\n",
    "ix_to_word = {ix: word for ix, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diplomatic': 0, 'through!': 1, 'who': 2, 'Princess': 3, 'portal': 4, 'smack': 5, 'has': 6, 'and': 7, 'They': 8, 'in': 9, 'goblins': 10, 'return': 11, 'have': 12, 'Fairy': 13, 'impending': 14, 'an': 15, 'meets': 16, 'Kara': 17, 'her': 18, 'that': 19, 'war': 20, 'bedroom': 21, 'to': 22, 'she': 23, \"Kara's\": 24, 'portal,': 25, 'huge': 26, 'task:': 27, 'end': 28, 'a': 29, 'To': 30, 'be': 31, 'astonishment,': 32, 'falls': 33, 'Selinda,': 34, 'appoints': 35, 'creatures,': 36, 'of': 37, 'through': 38, 'impossible': 39, 'fallen': 40, 'put': 41, 'closet': 42, 'fairy': 43, 'drafted': 44, 'into': 45, 'two': 46, 'attempt': 47, 'In': 48, 'refuse': 49, 'war.': 50, 'middle': 51, 'discovers': 52, 'for': 53, 'Queen': 54, 'opened': 55, 'assigns': 56, 'using': 57, 'the': 58, 'realms': 59, 'roust': 60, 'skills.': 61, 'pesky': 62, 'as': 63}\n"
     ]
    }
   ],
   "source": [
    "# смотрим отображения слов в элементы Python’овского словаря\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'diplomatic', 1: 'through!', 2: 'who', 3: 'Princess', 4: 'portal', 5: 'smack', 6: 'has', 7: 'and', 8: 'They', 9: 'in', 10: 'goblins', 11: 'return', 12: 'have', 13: 'Fairy', 14: 'impending', 15: 'an', 16: 'meets', 17: 'Kara', 18: 'her', 19: 'that', 20: 'war', 21: 'bedroom', 22: 'to', 23: 'she', 24: \"Kara's\", 25: 'portal,', 26: 'huge', 27: 'task:', 28: 'end', 29: 'a', 30: 'To', 31: 'be', 32: 'astonishment,', 33: 'falls', 34: 'Selinda,', 35: 'appoints', 36: 'creatures,', 37: 'of', 38: 'through', 39: 'impossible', 40: 'fallen', 41: 'put', 42: 'closet', 43: 'fairy', 44: 'drafted', 45: 'into', 46: 'two', 47: 'attempt', 48: 'In', 49: 'refuse', 50: 'war.', 51: 'middle', 52: 'discovers', 53: 'for', 54: 'Queen', 55: 'opened', 56: 'assigns', 57: 'using', 58: 'the', 59: 'realms', 60: 'roust', 61: 'skills.', 62: 'pesky', 63: 'as'}\n"
     ]
    }
   ],
   "source": [
    "# смотрим отображения элементов Python’овского словаря в слова\n",
    "print(ix_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пишем функцию для создания контекстного вектора \n",
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "# получаем примеры для обучения, семплируя из текста - списка слов\n",
    "# по контекстному окну\n",
    "data = []\n",
    "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1], \n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['To', \"Kara's\", 'she', 'discovers'], 'astonishment,'),\n",
       " ([\"Kara's\", 'astonishment,', 'discovers', 'that'], 'she'),\n",
       " (['astonishment,', 'she', 'that', 'a'], 'discovers'),\n",
       " (['she', 'discovers', 'a', 'portal'], 'that'),\n",
       " (['discovers', 'that', 'portal', 'has'], 'a'),\n",
       " (['that', 'a', 'has', 'opened'], 'portal'),\n",
       " (['a', 'portal', 'opened', 'in'], 'has'),\n",
       " (['portal', 'has', 'in', 'her'], 'opened'),\n",
       " (['has', 'opened', 'her', 'bedroom'], 'in'),\n",
       " (['opened', 'in', 'bedroom', 'closet'], 'her'),\n",
       " (['in', 'her', 'closet', 'and'], 'bedroom'),\n",
       " (['her', 'bedroom', 'and', 'two'], 'closet'),\n",
       " (['bedroom', 'closet', 'two', 'goblins'], 'and'),\n",
       " (['closet', 'and', 'goblins', 'have'], 'two'),\n",
       " (['and', 'two', 'have', 'fallen'], 'goblins'),\n",
       " (['two', 'goblins', 'fallen', 'through!'], 'have'),\n",
       " (['goblins', 'have', 'through!', 'They'], 'fallen'),\n",
       " (['have', 'fallen', 'They', 'refuse'], 'through!'),\n",
       " (['fallen', 'through!', 'refuse', 'to'], 'They'),\n",
       " (['through!', 'They', 'to', 'return'], 'refuse'),\n",
       " (['They', 'refuse', 'return', 'to'], 'to'),\n",
       " (['refuse', 'to', 'to', 'the'], 'return'),\n",
       " (['to', 'return', 'the', 'fairy'], 'to'),\n",
       " (['return', 'to', 'fairy', 'realms'], 'the'),\n",
       " (['to', 'the', 'realms', 'and'], 'fairy'),\n",
       " (['the', 'fairy', 'and', 'be'], 'realms'),\n",
       " (['fairy', 'realms', 'be', 'drafted'], 'and'),\n",
       " (['realms', 'and', 'drafted', 'for'], 'be'),\n",
       " (['and', 'be', 'for', 'an'], 'drafted'),\n",
       " (['be', 'drafted', 'an', 'impending'], 'for'),\n",
       " (['drafted', 'for', 'impending', 'war.'], 'an'),\n",
       " (['for', 'an', 'war.', 'In'], 'impending'),\n",
       " (['an', 'impending', 'In', 'an'], 'war.'),\n",
       " (['impending', 'war.', 'an', 'attempt'], 'In'),\n",
       " (['war.', 'In', 'attempt', 'to'], 'an'),\n",
       " (['In', 'an', 'to', 'roust'], 'attempt'),\n",
       " (['an', 'attempt', 'roust', 'the'], 'to'),\n",
       " (['attempt', 'to', 'the', 'pesky'], 'roust'),\n",
       " (['to', 'roust', 'pesky', 'creatures,'], 'the'),\n",
       " (['roust', 'the', 'creatures,', 'Kara'], 'pesky'),\n",
       " (['the', 'pesky', 'Kara', 'falls'], 'creatures,'),\n",
       " (['pesky', 'creatures,', 'falls', 'through'], 'Kara'),\n",
       " (['creatures,', 'Kara', 'through', 'the'], 'falls'),\n",
       " (['Kara', 'falls', 'the', 'portal,'], 'through'),\n",
       " (['falls', 'through', 'portal,', 'smack'], 'the'),\n",
       " (['through', 'the', 'smack', 'into'], 'portal,'),\n",
       " (['the', 'portal,', 'into', 'the'], 'smack'),\n",
       " (['portal,', 'smack', 'the', 'middle'], 'into'),\n",
       " (['smack', 'into', 'middle', 'of'], 'the'),\n",
       " (['into', 'the', 'of', 'a'], 'middle'),\n",
       " (['the', 'middle', 'a', 'huge'], 'of'),\n",
       " (['middle', 'of', 'huge', 'war.'], 'a'),\n",
       " (['of', 'a', 'war.', 'Kara'], 'huge'),\n",
       " (['a', 'huge', 'Kara', 'meets'], 'war.'),\n",
       " (['huge', 'war.', 'meets', 'Queen'], 'Kara'),\n",
       " (['war.', 'Kara', 'Queen', 'Selinda,'], 'meets'),\n",
       " (['Kara', 'meets', 'Selinda,', 'who'], 'Queen'),\n",
       " (['meets', 'Queen', 'who', 'appoints'], 'Selinda,'),\n",
       " (['Queen', 'Selinda,', 'appoints', 'Kara'], 'who'),\n",
       " (['Selinda,', 'who', 'Kara', 'as'], 'appoints'),\n",
       " (['who', 'appoints', 'as', 'a'], 'Kara'),\n",
       " (['appoints', 'Kara', 'a', 'Fairy'], 'as'),\n",
       " (['Kara', 'as', 'Fairy', 'Princess'], 'a'),\n",
       " (['as', 'a', 'Princess', 'and'], 'Fairy'),\n",
       " (['a', 'Fairy', 'and', 'assigns'], 'Princess'),\n",
       " (['Fairy', 'Princess', 'assigns', 'her'], 'and'),\n",
       " (['Princess', 'and', 'her', 'an'], 'assigns'),\n",
       " (['and', 'assigns', 'an', 'impossible'], 'her'),\n",
       " (['assigns', 'her', 'impossible', 'task:'], 'an'),\n",
       " (['her', 'an', 'task:', 'to'], 'impossible'),\n",
       " (['an', 'impossible', 'to', 'put'], 'task:'),\n",
       " (['impossible', 'task:', 'put', 'an'], 'to'),\n",
       " (['task:', 'to', 'an', 'end'], 'put'),\n",
       " (['to', 'put', 'end', 'to'], 'an'),\n",
       " (['put', 'an', 'to', 'the'], 'end'),\n",
       " (['an', 'end', 'the', 'war'], 'to'),\n",
       " (['end', 'to', 'war', 'using'], 'the'),\n",
       " (['to', 'the', 'using', 'her'], 'war'),\n",
       " (['the', 'war', 'her', 'diplomatic'], 'using'),\n",
       " (['war', 'using', 'diplomatic', 'skills.'], 'her')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# мы получаем список двухэлементных кортежей, первый элемент -\n",
    "# переменная X (контекстное окно - 2 слова слева, 2 слова справа),\n",
    "# второй элемент - зависимая переменная (интересующее нас слово),\n",
    "# вы видите, что теперь мы создаем слова близко друг к другу\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim\n",
    "    ):  # мы передаем размер словаря (vocab_size) и размерность\n",
    "        # матрицы эмбеддингов (embedding_dim) в виде гиперпараметров\n",
    "        super(CBOW, self).__init__()\n",
    "\n",
    "        # вывод: 1 x embedding_dim\n",
    "        # инициализируем матрицу эмбеддингов, исходя из входных данных\n",
    "        # Embedding(64, 100)\n",
    "        self.embeddings = nn.Embedding(\n",
    "            vocab_size, embedding_dim\n",
    "        )\n",
    "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "        self.activation_function1 = nn.ReLU()\n",
    "\n",
    "        # вывод: 1 x vocab_size\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        self.activation_function2 = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = sum(self.embeddings(inputs)).view(1, -1)\n",
    "        out = self.linear1(embeds)\n",
    "        out = self.activation_function1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.activation_function2(out)\n",
    "        return out\n",
    "\n",
    "    def get_word_emdedding(self, word):\n",
    "        word = torch.tensor([word_to_ix[word]])\n",
    "        # поиск одного слова в Embedding-слое после \n",
    "        # оптимизации Embedding-слоя\n",
    "        return self.embeddings(word).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мы инициализируем модель\n",
    "\n",
    "model = CBOW(vocab_size, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 17:28:50.007512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# задаем функцию потерь и оптимизатор\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "конец эпохи 0 | функция потерь 341.410\n",
      "конец эпохи 1 | функция потерь 329.548\n",
      "конец эпохи 2 | функция потерь 318.385\n",
      "конец эпохи 3 | функция потерь 307.745\n",
      "конец эпохи 4 | функция потерь 297.539\n",
      "конец эпохи 5 | функция потерь 287.680\n",
      "конец эпохи 6 | функция потерь 278.142\n",
      "конец эпохи 7 | функция потерь 268.879\n",
      "конец эпохи 8 | функция потерь 259.886\n",
      "конец эпохи 9 | функция потерь 251.095\n",
      "конец эпохи 10 | функция потерь 242.463\n",
      "конец эпохи 11 | функция потерь 233.953\n",
      "конец эпохи 12 | функция потерь 225.584\n",
      "конец эпохи 13 | функция потерь 217.299\n",
      "конец эпохи 14 | функция потерь 209.169\n",
      "конец эпохи 15 | функция потерь 201.178\n",
      "конец эпохи 16 | функция потерь 193.297\n",
      "конец эпохи 17 | функция потерь 185.538\n",
      "конец эпохи 18 | функция потерь 177.900\n",
      "конец эпохи 19 | функция потерь 170.370\n",
      "конец эпохи 20 | функция потерь 162.943\n",
      "конец эпохи 21 | функция потерь 155.625\n",
      "конец эпохи 22 | функция потерь 148.443\n",
      "конец эпохи 23 | функция потерь 141.413\n",
      "конец эпохи 24 | функция потерь 134.521\n",
      "конец эпохи 25 | функция потерь 127.769\n",
      "конец эпохи 26 | функция потерь 121.163\n",
      "конец эпохи 27 | функция потерь 114.739\n",
      "конец эпохи 28 | функция потерь 108.514\n",
      "конец эпохи 29 | функция потерь 102.504\n",
      "конец эпохи 30 | функция потерь 96.723\n",
      "конец эпохи 31 | функция потерь 91.190\n",
      "конец эпохи 32 | функция потерь 85.920\n",
      "конец эпохи 33 | функция потерь 80.905\n",
      "конец эпохи 34 | функция потерь 76.134\n",
      "конец эпохи 35 | функция потерь 71.641\n",
      "конец эпохи 36 | функция потерь 67.403\n",
      "конец эпохи 37 | функция потерь 63.427\n",
      "конец эпохи 38 | функция потерь 59.704\n",
      "конец эпохи 39 | функция потерь 56.238\n",
      "конец эпохи 40 | функция потерь 53.014\n",
      "конец эпохи 41 | функция потерь 50.016\n",
      "конец эпохи 42 | функция потерь 47.237\n",
      "конец эпохи 43 | функция потерь 44.659\n",
      "конец эпохи 44 | функция потерь 42.266\n",
      "конец эпохи 45 | функция потерь 40.052\n",
      "конец эпохи 46 | функция потерь 38.001\n",
      "конец эпохи 47 | функция потерь 36.096\n",
      "конец эпохи 48 | функция потерь 34.335\n",
      "конец эпохи 49 | функция потерь 32.701\n"
     ]
    }
   ],
   "source": [
    "# обучение\n",
    "\n",
    "for epoch in range(50):\n",
    "    # начинаем отслеживать, насколько точны \n",
    "    # наши слова\n",
    "    total_loss = 0\n",
    "\n",
    "    # проходим по всем обучающим данным (x, y)\n",
    "    for context, target in data:\n",
    "        context_vector = make_context_vector(context, word_to_ix)\n",
    "\n",
    "        # логвероятности\n",
    "        log_probs = model(context_vector)\n",
    "\n",
    "        # вычисляем ошибки, сравниваем фактическое целевое слово\n",
    "        # с предсказанными логвероятностями\n",
    "        total_loss += loss_function(log_probs, \n",
    "                                    torch.tensor([word_to_ix[target]]))\n",
    "        \n",
    "\n",
    "    # оптимизируем в конце каждой эпохи\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # выводим некоторые метрики, чтобы увидеть, уменьшается ли ошибка\n",
    "    print(\"конец эпохи {} | функция потерь {:2.3f}\".format(epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.9854, -4.4660, -4.7435, -5.9982, -4.9423, -4.2821, -3.9465, -5.3258,\n",
       "         -5.2978, -4.2817, -4.7616, -5.1793, -5.5720, -4.9780, -6.1901, -4.5477,\n",
       "         -4.5531, -2.5600, -5.3023, -3.1733, -4.8637, -5.5714, -3.5211, -5.0773,\n",
       "         -6.9901, -4.6496, -4.5390, -5.1079, -5.2634, -4.1721, -6.0281, -5.1387,\n",
       "         -5.1415, -3.4748, -6.1279, -5.0649, -1.8627, -5.0629, -1.7432, -5.6957,\n",
       "         -5.6831, -5.7368, -4.5809, -4.7182, -4.9837, -4.8950, -5.9325, -4.9519,\n",
       "         -6.2756, -5.2920, -5.1967, -3.8832, -4.1986, -5.6002, -5.3116, -3.7686,\n",
       "         -5.3708, -3.8020, -3.9647, -4.4381, -4.7890, -5.2009, -3.1667, -5.0154]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь давайте проверим, предсказывает ли модель \n",
    "# правильное слово, используя наши исходные данные\n",
    "context = [\"Kara\", \"falls\", \"the\", \"portal\"]\n",
    "context_vector = make_context_vector(context, word_to_ix)\n",
    "# получаем вектор логвероятностей для заданного контекстного окна\n",
    "a = model(context_vector)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diplomatic': -5.99, 'through!': -4.47, 'who': -4.74, 'Princess': -6.0, 'portal': -4.94, 'smack': -4.28, 'has': -3.95, 'and': -5.33, 'They': -5.3, 'in': -4.28, 'goblins': -4.76, 'return': -5.18, 'have': -5.57, 'Fairy': -4.98, 'impending': -6.19, 'an': -4.55, 'meets': -4.55, 'Kara': -2.56, 'her': -5.3, 'that': -3.17, 'war': -4.86, 'bedroom': -5.57, 'to': -3.52, 'she': -5.08, \"Kara's\": -6.99, 'portal,': -4.65, 'huge': -4.54, 'task:': -5.11, 'end': -5.26, 'a': -4.17, 'To': -6.03, 'be': -5.14, 'astonishment,': -5.14, 'falls': -3.47, 'Selinda,': -6.13, 'appoints': -5.06, 'creatures,': -1.86, 'of': -5.06, 'through': -1.74, 'impossible': -5.7, 'fallen': -5.68, 'put': -5.74, 'closet': -4.58, 'fairy': -4.72, 'drafted': -4.98, 'into': -4.89, 'two': -5.93, 'attempt': -4.95, 'In': -6.28, 'refuse': -5.29, 'war.': -5.2, 'middle': -3.88, 'discovers': -4.2, 'for': -5.6, 'Queen': -5.31, 'opened': -3.77, 'assigns': -5.37, 'using': -3.8, 'the': -3.96, 'realms': -4.44, 'roust': -4.79, 'skills.': -5.2, 'pesky': -3.17, 'as': -5.02}\n"
     ]
    }
   ],
   "source": [
    "# сопоставим логвероятности словам словаря\n",
    "import numpy as np\n",
    "values_list = list(ix_to_word.values())\n",
    "result_dict = {word: a[0, i].item() for i, word in enumerate(values_list)}\n",
    "rounded_dict = {key: round(value, 2) for key, value in result_dict.items()}\n",
    "print(rounded_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: To Kara's astonishment, she discovers that a portal has opened in her bedroom closet and two goblins have fallen through! They refuse to return to the fairy realms and be drafted for an impending war. In an attempt to roust the pesky creatures, Kara falls through the portal, smack into the middle of a huge war. Kara meets Queen Selinda, who appoints Kara as a Fairy Princess and assigns her an impossible task: to put an end to the war using her diplomatic skills.\n",
      "\n",
      "Контекст: ['Kara', 'falls', 'the', 'portal']\n",
      "\n",
      "Прогноз: through\n"
     ]
    }
   ],
   "source": [
    "print(f'Исходный текст: {\" \".join(raw_text)}\\n')\n",
    "print(f\"Контекст: {context}\\n\")\n",
    "print(f\"Прогноз: {ix_to_word[torch.argmax(a[0]).item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Получаем векторы для последовательностей:\n",
      " tensor([[-1.0090e+00, -1.2199e+00,  2.6711e-01,  1.7890e+00,  6.9306e-01,\n",
      "          1.1203e+00,  8.0827e-02, -8.3560e-01, -1.2842e+00, -1.5991e-01,\n",
      "         -8.3993e-01,  2.0076e+00,  9.4046e-01,  1.4451e+00,  4.4093e-01,\n",
      "         -1.9838e+00,  4.8109e-01, -5.4800e-01, -1.1622e+00,  6.2339e-01,\n",
      "          1.3167e-02, -6.6875e-01, -5.0148e-01,  1.5097e+00,  8.9932e-02,\n",
      "         -9.6222e-01, -1.1459e+00,  5.5924e-01, -1.7697e+00, -4.0415e-01,\n",
      "          4.3648e-01,  1.3770e+00,  4.3573e-01,  1.1972e+00, -1.3504e+00,\n",
      "          8.5452e-01, -1.1214e-01, -9.5374e-01, -2.5653e-01, -6.9154e-01,\n",
      "          1.1581e+00,  1.0974e-01,  2.6138e-01, -1.3512e+00, -4.0799e-01,\n",
      "          1.8491e-01, -5.1875e-01,  1.4990e+00, -4.9743e-02, -1.2241e+00,\n",
      "         -2.7252e-01,  1.9608e-01, -1.0414e+00, -6.8224e-01,  9.2100e-01,\n",
      "          1.4488e+00, -9.3083e-01, -2.2348e-01,  2.2392e+00, -7.2344e-01,\n",
      "          6.5876e-01,  7.4684e-01,  2.2105e+00, -5.7948e-02,  1.2236e+00,\n",
      "          4.9773e-01,  9.8627e-02,  1.3416e-01, -2.0259e+00, -4.9855e-01,\n",
      "         -5.4841e-02,  1.2435e+00,  1.0405e+00,  1.1321e+00,  1.1032e-02,\n",
      "         -1.4557e+00, -5.6456e-02,  1.2797e+00, -2.2687e-01,  1.0563e+00,\n",
      "          1.1891e+00, -8.4920e-01,  6.7204e-01,  4.3381e-01,  8.0912e-01,\n",
      "         -7.7683e-01,  1.1157e-01, -1.5418e+00, -2.2133e-01, -1.2280e+00,\n",
      "         -4.5340e-01, -1.3431e+00,  1.1260e+00,  5.4815e-01,  8.0195e-02,\n",
      "          9.6987e-01, -1.3517e+00, -1.1119e-01, -8.1762e-02,  1.4487e+00],\n",
      "        [-1.4824e+00,  6.1293e-01, -1.8989e+00, -1.8513e+00,  8.0619e-01,\n",
      "          9.5402e-01,  8.5164e-01, -1.0217e+00,  5.2872e-02, -5.5031e-01,\n",
      "          1.5772e+00,  8.4257e-01, -4.1703e-01,  1.6226e+00, -5.3659e-01,\n",
      "         -7.7246e-01, -8.4910e-01, -1.3069e+00, -1.0842e+00,  9.1098e-01,\n",
      "         -8.3092e-01,  3.8808e-01, -3.8408e-01,  1.5447e+00, -6.3397e-01,\n",
      "          5.3844e-01,  1.0612e+00, -1.4471e-01,  1.5636e+00,  4.7230e-01,\n",
      "          1.3900e-03,  7.7919e-01, -1.2583e+00,  1.7664e-02, -1.7387e+00,\n",
      "          2.2990e+00,  1.4360e-01,  6.5184e-01, -3.4714e-01, -2.0519e-01,\n",
      "          9.6160e-01,  3.3839e-01, -5.1636e-02,  2.9531e-02,  1.1504e+00,\n",
      "         -1.8122e+00, -1.5565e+00,  7.5650e-01, -6.0148e-02, -1.4680e+00,\n",
      "         -4.3623e-02, -7.6278e-01, -2.6929e-01,  6.5515e-01,  1.0683e+00,\n",
      "         -6.1975e-01, -1.2971e+00,  6.3463e-02,  1.7351e-01,  5.1197e-01,\n",
      "         -6.4603e-01,  6.3870e-01, -9.7518e-01,  7.5576e-01,  1.0767e-01,\n",
      "          1.9831e+00, -1.7054e-01, -2.9602e-01,  2.6017e-01, -1.1559e-02,\n",
      "         -8.6627e-01, -7.5948e-01,  2.0205e+00,  1.8149e+00, -1.3234e-01,\n",
      "          1.2998e+00, -1.8165e+00, -3.0161e-02,  4.1406e-01, -1.0270e+00,\n",
      "          1.4963e+00,  2.0662e+00,  6.0164e-01, -9.7617e-01, -6.5118e-01,\n",
      "          1.5996e+00, -1.1596e+00, -1.9600e+00,  5.8087e-01,  3.3167e-01,\n",
      "         -5.3793e-01,  3.1231e+00, -2.2126e-03, -1.1518e-02,  1.4963e+00,\n",
      "          5.5520e-01, -2.3991e-01,  1.3334e+00,  3.9667e-01, -3.1915e-01],\n",
      "        [ 1.4056e+00,  1.3452e+00, -1.7866e+00, -2.8012e-01,  5.1436e-01,\n",
      "         -3.5484e-01,  1.4946e-01,  1.5211e-01,  3.2393e+00,  1.2194e+00,\n",
      "          2.5809e-01, -6.4411e-01,  2.0390e-02,  6.7934e-01, -9.9787e-01,\n",
      "          1.4571e+00,  6.3418e-01,  7.3845e-01, -1.1428e+00, -1.5408e+00,\n",
      "         -1.9185e+00,  1.6719e+00, -4.3015e-01, -6.9902e-02,  1.7118e+00,\n",
      "         -1.2670e+00, -7.4563e-01, -4.5342e-01, -5.8967e-01,  2.0271e+00,\n",
      "         -4.3234e-02,  3.1077e-01, -1.8557e+00,  3.1917e-01, -7.6498e-01,\n",
      "         -9.9113e-01,  3.4403e-01,  2.7384e-01, -3.3400e-01, -1.5587e+00,\n",
      "         -1.2960e-01, -3.4011e-01, -6.9787e-01,  2.1680e+00, -8.5479e-01,\n",
      "          6.7738e-01, -1.1649e+00,  1.1769e-01, -3.7482e-01, -8.7820e-01,\n",
      "         -5.6685e-01,  1.8240e-01,  3.2844e-02,  2.0351e+00,  1.1833e+00,\n",
      "          1.2430e+00, -1.0602e+00,  4.0081e-01, -8.6961e-01, -1.2565e+00,\n",
      "         -2.6230e-02,  5.7250e-01, -6.9887e-01,  8.8148e-01,  7.3998e-01,\n",
      "          1.9644e+00,  1.8250e-01,  1.0875e+00, -2.4577e-01, -1.1961e+00,\n",
      "         -6.3051e-01,  4.6046e-01, -1.5540e+00, -1.4376e+00,  3.7012e-01,\n",
      "          5.4768e-01,  8.0958e-02, -2.1975e-01,  1.5356e+00, -1.9598e-01,\n",
      "         -1.2438e+00, -2.0787e+00,  5.6961e-02,  1.3889e+00,  1.1532e+00,\n",
      "          4.5853e-02, -1.4479e+00,  1.7487e-01, -1.1699e+00,  1.3541e+00,\n",
      "         -5.2330e-01,  2.9995e-01,  3.0559e-01,  9.9591e-01,  1.6970e+00,\n",
      "          7.9287e-01, -6.6321e-01,  9.4426e-01, -3.3817e-01, -6.8686e-01]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# теперь давайте получим то, что нас интересует, а именно эмбеддинги\n",
    "print(f\"Получаем векторы для последовательностей:\\n\", \n",
    "      model.embeddings(torch.LongTensor([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Получаем веса:\n",
      " tensor([-1.0090, -1.2199,  0.2671,  1.7890,  0.6931,  1.1203,  0.0808, -0.8356,\n",
      "        -1.2842, -0.1599, -0.8399,  2.0076,  0.9405,  1.4451,  0.4409, -1.9838,\n",
      "         0.4811, -0.5480, -1.1622,  0.6234,  0.0132, -0.6687, -0.5015,  1.5097,\n",
      "         0.0899, -0.9622, -1.1459,  0.5592, -1.7697, -0.4041,  0.4365,  1.3770,\n",
      "         0.4357,  1.1972, -1.3504,  0.8545, -0.1121, -0.9537, -0.2565, -0.6915,\n",
      "         1.1581,  0.1097,  0.2614, -1.3512, -0.4080,  0.1849, -0.5187,  1.4990,\n",
      "        -0.0497, -1.2241, -0.2725,  0.1961, -1.0414, -0.6822,  0.9210,  1.4488,\n",
      "        -0.9308, -0.2235,  2.2392, -0.7234,  0.6588,  0.7468,  2.2105, -0.0579,\n",
      "         1.2236,  0.4977,  0.0986,  0.1342, -2.0259, -0.4986, -0.0548,  1.2435,\n",
      "         1.0405,  1.1321,  0.0110, -1.4557, -0.0565,  1.2797, -0.2269,  1.0563,\n",
      "         1.1891, -0.8492,  0.6720,  0.4338,  0.8091, -0.7768,  0.1116, -1.5418,\n",
      "        -0.2213, -1.2280, -0.4534, -1.3431,  1.1260,  0.5482,  0.0802,  0.9699,\n",
      "        -1.3517, -0.1112, -0.0818,  1.4487])\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Получаем веса:\\n\", model.embeddings.weight.data[1]\n",
    ")  # мы можем получить всю матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмбеддинг для Kara:\n",
      "tensor([ 0.1775, -0.8194, -0.1095,  0.7376,  1.6377,  0.8093,  0.6530, -0.5605,\n",
      "         0.3553,  0.4160, -0.4884, -0.1703,  0.6380, -2.2777,  0.6554,  0.0107,\n",
      "         1.1062, -0.1409, -1.5782, -0.2817, -0.8835, -0.1846,  0.1745,  1.1490,\n",
      "         0.2203,  0.4399, -0.6069,  1.0812,  1.0867, -0.2677, -0.7717, -0.0371,\n",
      "        -1.0458, -0.1202,  0.1830, -0.0294, -0.6084, -0.2098,  0.9619,  0.5723,\n",
      "         0.7324, -0.4089, -1.3489, -1.3197,  1.5507,  0.1014,  0.7550, -1.1809,\n",
      "         1.6273,  1.1813,  0.7977,  1.3293, -0.3964, -0.6034, -0.0787,  0.9559,\n",
      "         0.8052,  0.4772, -0.6348, -0.9767,  1.9693,  0.8498,  0.4780, -1.2588,\n",
      "        -0.3836, -0.7493, -1.2636,  0.6499,  1.0618,  1.6500, -0.3296, -0.7557,\n",
      "        -0.7746,  0.1822,  0.3142,  0.0068,  1.0691, -1.7755, -0.2767,  0.9810,\n",
      "         1.6947, -0.5697, -0.2470, -0.9102, -0.5590, -0.0069, -1.5698,  0.2673,\n",
      "         0.6795,  0.0878, -0.4846,  1.6257,  1.9266,  1.1159,  0.7326,  1.1466,\n",
      "         0.8172, -0.1877,  0.5013, -0.4327], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# а на самом деле нам важна возможность поиска \n",
    "# отдельных слов с помощью их эмбеддингов\n",
    "torch.set_printoptions(threshold=10_000)\n",
    "print(f\"Эмбеддинг для Kara:\\n{model.embeddings.weight[word_to_ix['Kara']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "7983be674d93518c54b39475eb68739ef6a55aa8f4ec8a69dd7da1e80860d970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
